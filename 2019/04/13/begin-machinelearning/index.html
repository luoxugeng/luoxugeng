<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><meta name="google-site-verification" content="hq5sRpd2t4HpGsWwIxrXzsnIb0QBcNnMpCt91cXxT7s"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"nemolaw.com",root:"/",scheme:"Mist",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"disqus",storage:!0,lazyload:!1,nav:null,activeClass:"disqus"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="每天唠叨多了,终于应该老老实实写读书笔记了.作为机器学习概念入门的书籍我觉得挺合适的.入门书籍关键是要讲清楚, 每个概念的由来,具体要解决什么问题,优缺点.知其所以然."><meta property="og:type" content="article"><meta property="og:title" content="(笔记) 白话机器学习算法"><meta property="og:url" content="https://nemolaw.com/2019/04/13/begin-machinelearning/index.html"><meta property="og:site_name" content="Nemo的轨迹"><meta property="og:description" content="每天唠叨多了,终于应该老老实实写读书笔记了.作为机器学习概念入门的书籍我觉得挺合适的.入门书籍关键是要讲清楚, 每个概念的由来,具体要解决什么问题,优缺点.知其所以然."><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://s3.amazonaws.com/nemolaw/doubotu.jpg"><meta property="og:image" content="https://s3.amazonaws.com/nemolaw/RegressionAnalysis.png"><meta property="og:image" content="https://s3.amazonaws.com/nemolaw/KNN.png"><meta property="og:image" content="https://s3.amazonaws.com/nemolaw/SVM.png"><meta property="og:image" content="https://s3.amazonaws.com/nemolaw/epsilon.png"><meta property="article:published_time" content="2019-04-13T15:17:08.000Z"><meta property="article:modified_time" content="2019-04-14T01:17:08.000Z"><meta property="article:author" content="NemoLaw"><meta property="article:tag" content="20%的收获"><meta property="article:tag" content="数理知识"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://s3.amazonaws.com/nemolaw/doubotu.jpg"><link rel="canonical" href="https://nemolaw.com/2019/04/13/begin-machinelearning/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>(笔记) 白话机器学习算法 | Nemo的轨迹</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-131534564-2"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-131534564-2")</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="Nemo的轨迹" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">Nemo的轨迹</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">work hard, be persistent, and good luck</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fas fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fas fa-address-card fa-fw"></i>关于我</a></li><li class="menu-item menu-item-sparethechild"><a href="/spare-the-child/" rel="section"><i class="fas fa-heart-broken fa-fw"></i>放过儿童项目</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://nemolaw.com/2019/04/13/begin-machinelearning/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/author.jpg"><meta itemprop="name" content="NemoLaw"><meta itemprop="description" content="但盼风雨来，能留你在此"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Nemo的轨迹"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">(笔记) 白话机器学习算法</h1><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-04-13 23:17:08" itemprop="dateCreated datePublished" datetime="2019-04-13T23:17:08+08:00">2019-04-13</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-04-14 09:17:08" itemprop="dateModified" datetime="2019-04-14T09:17:08+08:00">2019-04-14</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E4%B9%A6%E5%BD%B1%E7%A9%BA%E9%97%B4/" itemprop="url" rel="index"><span itemprop="name">书影空间</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Disqus：</span> <a title="disqus" href="/2019/04/13/begin-machinelearning/#disqus_thread" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/04/13/begin-machinelearning/" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.8k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span><div class="post-description">每天唠叨多了,终于应该老老实实写读书笔记了.作为机器学习概念入门的书籍我觉得挺合适的.入门书籍关键是要讲清楚, 每个概念的由来,具体要解决什么问题,优缺点.知其所以然.</div></header><div class="post-body" itemprop="articleBody"><ul><li>[数据科学的四个步骤](# 数据科学的四个步骤)<ul><li>[数据的准备](# 数据的准备)</li><li>[为模型选择合适的算法 (书的重点)](# 为模型选择合适的算法 - 书的重点)</li><li>[调整算法参数，优化模型](# 调整算法参数优化模型)</li><li>[根据准确度评价模型](# 根据准确度评价模型)</li></ul></li><li>[算法](# 算法)<ul><li>[无监督学习](# 无监督学习)<ul><li>[K 均值聚类](#k 均值聚类)</li><li>[主成分分析](# 主成分分析)</li><li>[关联规则](# 关联规则)</li><li>[社会网络分析](# 社会网络分析)</li></ul></li><li>[监督学习](# 监督学习)<ul><li>[回归分析](# 回归分析)</li><li>[K 最近邻](#k 最近邻)</li><li>[支持向量机](# 支持向量机)</li><li>[决策树 和 随机森林](# 决策树 - 和 - 随机森林)</li><li>[神经网络](# 神经网络)</li></ul></li><li>[A/Btest 和 多臂老虎机](#abtest - 和 - 多臂老虎机)</li></ul></li><li>[总结](# 总结)<h2 id="数据科学的四个步骤"><a href="#数据科学的四个步骤" class="headerlink" title="数据科学的四个步骤"></a>数据科学的四个步骤</h2></li></ul><h3 id="数据的准备"><a href="#数据的准备" class="headerlink" title="数据的准备"></a>数据的准备</h3><ol><li>变量的确定：变量也叫 属性，特征 或 维度</li></ol><ul><li><p>二值变量</p></li><li><p>分类变量</p></li><li><p>整型变量</p></li><li><p>连续变量</p></li></ul><ol start="2"><li><p>变量选择：变量选择是一个试错的过程，，需要根据反馈结果不断更换变量</p></li><li><p>特征工程：本质是对变量的处理，得到更普遍性的维度</p></li></ol><ul><li><p>重新编码：两个不同变量有明显的从属关系</p></li><li><p>降维：合并多个变量</p></li></ul><ol start="4"><li>数据修复</li></ol><ul><li>近似</li><li>计算</li><li>移除</li></ul><h3 id="为模型选择合适的算法-书的重点"><a href="#为模型选择合适的算法-书的重点" class="headerlink" title="为模型选择合适的算法 (书的重点)"></a>为模型选择合适的算法 (书的重点)</h3><ol><li>无监督学习:<br>任务目标：指出数据中隐藏的模式。之所以称之为无监 督学习算法，是因为我们不知道要找的模式是什么，而是要依靠算法从 数据集中发现模式.</li></ol><ul><li><p>K 均值聚类</p></li><li><p>主成分分析 (PCA)</p></li><li><p>关联规则</p></li><li><p>社会网络分析</p></li></ul><ol start="2"><li>监督学习:<br>任务目标：使用数据中的模式做预测。之所以称之为监督学习算 法，是因为它们的预测都基于已有的模式.</li></ol><ul><li><p>回归分析 (Regression Analysis)</p></li><li><p>K 最近邻 (KNN)</p></li><li><p>支持向量机 (SVM)</p></li><li><p>决策树</p></li><li><p>随机森林 (random decision forests)</p></li><li><p>神经网络</p></li></ul><ol start="3"><li>强化学习:</li></ol><p>无监督学习模型和监督学习模型在部署之后便无法更改。强化学习不同于此.<br>强化学习模型自身可以通过反馈结果不断改进.</p><ul><li>A/Btest</li></ul><h3 id="调整算法参数，优化模型"><a href="#调整算法参数，优化模型" class="headerlink" title="调整算法参数，优化模型"></a>调整算法参数，优化模型</h3><p>参数调优:<br>从结果来看，参数调节会产生三种结果</p><ul><li><p>过拟合：实践中我们更多遇到的。对已有数据拟合度最高，但可能使未知数据的预测准确度下降</p></li><li><p>理想拟合：在数据趋势和细微变化中取得平衡</p></li><li><p>欠拟合：忽视数据中的基本模式，导致没有正确表现出数据的趋势</p></li></ul><p>实践中我们经常会遇到过拟合的问题 ( 想想为什么 ). 解决方式之一就是引入 惩罚参数.</p><h3 id="根据准确度评价模型"><a href="#根据准确度评价模型" class="headerlink" title="根据准确度评价模型"></a>根据准确度评价模型</h3><ol><li>使用指标</li></ol><p>常用的指标有:</p><p>1.1 准确率</p><p>到底管不管用，最简单的一个指标就是：你到底成功预测的占比有多少</p><p>1.2 混淆矩阵<br>[type-1 error 和 type-2 error ](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 第一型及第二型錯誤)</p><p>关心两种错误记忆方式</p><ul><li><p>type-1 error: 本来是对的，被弄成错的</p></li><li><p>type-2 error: 本来是错的，预计成对的。例如男生怀孕了</p></li></ul><p>1.3 均方根误差</p><ul><li><p>用来衡量预测值和实际值之间的误差</p></li><li><p>因为每个误差都取了平方，所以大误差就被放大 了。这使得均方根误差对异常值极其敏感，对这些值的惩罚力度也更大.</p></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><h4 id="K-均值聚类"><a href="#K-均值聚类" class="headerlink" title="K 均值聚类"></a>K 均值聚类</h4><p>一句话描述：个体最可能属于哪个类别</p><p>应用举例：把顾客或产品分入不同的群组，其中 k 表示群组个数.</p><p>[wiki](<a href="https://zh.wikipedia.org/wiki/K" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/K</a> - 平均算法)</p><p>在定义群组时，必须回答两个问题</p><ul><li>有多少个群组？(群组数量 k 必须事先指定)</li></ul><p>K 的确定常用陡坡图.</p><ul><li>每个群组中有谁？( 认为每个数据点都是平等，不会有类似嵌套的关系 )</li></ul><p>优点：简单朴素</p><p>局限性</p><ul><li><p>每个数据点只能属于一个群组.</p></li><li><p>群组被假定是正圆形的：假设群组的实际形状是椭圆形，那么在应用 k 均值聚类方法之后，位于椭圆两端的数据点可能会 被划入邻近的群组</p></li><li><p>群组被假定是离散的. k 均值聚类既不允许群组重叠，也不允许 它们相互嵌套</p></li></ul><p><img src="https://s3.amazonaws.com/nemolaw/doubotu.jpg" alt="陡坡图"></p><h4 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h4><p>一句话介绍：个体最明显的特征是什么</p><p>主成分分析是一种降维技巧，它使得我们可以使用较少的变量来描述数据，这些变量即为主成分.</p><p>[wiki](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 主成分分析)</p><p>局限性:</p><ul><li>散度最大化：这是主成分分析的前提. (即对数据点最分散的维度是最有用的)</li><li>正交成分：主成分分析算法总是生成正交主成分，即成分之间 存在正交关系。然而，这个假设可能不正确，因为信息维度之 间可能不存在正交关系.</li><li>解释成分：主成分分析算法面临的一个重大难题是，必须对其 产生的成分进行解释。但有时，可能很难解释变量按某种方式 进行组合的原因.</li></ul><h4 id="关联规则"><a href="#关联规则" class="headerlink" title="关联规则"></a>关联规则</h4><p>一句话介绍：个体之间关系是怎么样的？</p><p>应用举例: <a href="https://book.douban.com/subject/3283973/" target="_blank" rel="noopener">啤酒与纸尿片</a></p><p>[wiki](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 关联规则学习)</p><p>识别关联规则的常用指标有 3 个</p><ul><li><p>支持度：指某个项集出现的频率占总交易数的比例</p></li><li><p>置信度：在 X 项出现的前提下，XY 两项同时出现的占比: P (XY)/P (X). 缺点是，置信度会错估某个关联规则的重要性</p></li><li><p>提升度：在 X 项，Y 项独立出现的前提下，XY 两项同时出现的占比: P (XY)/ {P (X) *P (Y)}</p></li></ul><p>评估关联规则实际是商品之间的组合，这是指数增长。可以减少组合个数的方法有</p><ul><li>先验规则：如果某个项集出现得不频繁，那么包含它的 任何更大的项集必定也出现得不频繁.</li></ul><p>局限性:</p><ul><li><p>计算成本大：尽管利用先验原则可以减少候选项集的个数，但是当 库存量很大或者支持度阈值很低时，候选项集仍然会很多。一个解决办 法是，使用高级数据结构对候选项集进行更高效的分类，从而减少比较 的次数.</p></li><li><p>假关联：当元素的数量很大时，偶尔会出现假关联。为了确保所发 现的关联规则具有普遍性，应该对它们进行验证</p></li></ul><h4 id="社会网络分析"><a href="#社会网络分析" class="headerlink" title="社会网络分析"></a>社会网络分析</h4><p>一句话介绍：当关系变得复杂，就需要分析一张关系网</p><p>应用举例: [六度分隔理论](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 六度分隔理论)</p><p>[wiki](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 社会网络 #社會網絡分析)</p><ol><li>Louvain 方法</li></ol><p>Louvain 方法 用来在网络中找出群组，它会尝试使用不同的聚类配 置来做如下两件事:</p><ul><li><p>把同一个群组中各个节点间的边数和强度最大化；</p></li><li><p>把属于不同群组的节点间的边数和强度最小化</p></li></ul><ol start="2"><li>PageRank 算法</li></ol><p>根据链接的数量，强度以及来源对网络中的节点 进行排序。这个算法有助于找出网络中占主导地位的节点，但 对链接数不太多的新节点并不友好</p><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><h4 id="回归分析"><a href="#回归分析" class="headerlink" title="回归分析"></a>回归分析</h4><p>[wiki](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 線性回歸)</p><p><img src="https://s3.amazonaws.com/nemolaw/RegressionAnalysis.png" alt="看图吧"></p><p>通过带权重的组合变量能够得到更准确的预测结果。有两个问题需要解决:</p><ul><li>如何得到最优权重组合？</li></ul><ol><li>梯度下降法</li></ol><p>似于一步步走到山底下，梯度下降法先初步猜测合适的权重组合，再通过迭代逼近更准确的精度</p><ol start="2"><li>随机梯度下降法</li></ol><p>一次梯度下降法 得到的结果有可能是极值，而不是最优值.</p><ul><li>如何解释它们？</li></ul><ol><li><p>[回归系数](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 線性回歸) : 回归预测变量权重的正式名称是回归系数</p></li><li><p><a href="">标准化回归系数</a>: 经过标准化之后，预测变量的系数被称为 标准化回归系数 可以作为不同关系强度的对比</p></li></ol><ul><li>适合场景</li></ul><ol><li><p>预测变量之间的关系不强</p></li><li><p>无异常值</p></li><li><p>趋势可以用直线表示 ( 也就是不适合趋势是曲线的)</p></li></ol><h4 id="K-最近邻"><a href="#K-最近邻" class="headerlink" title="K 最近邻"></a>K 最近邻</h4><p>一句话介绍：物以类聚</p><p><img src="https://s3.amazonaws.com/nemolaw/KNN.png" alt="看图吧"></p><p>[wiki](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 最近鄰居法)</p><p>特点:</p><ul><li><p>k 最近邻算法根据周围数据点的类型对某个数据点进行分类.</p></li><li><p>k 表示用作参考的数据点的个数，可以使用交叉验证法来确定.</p></li><li><p>当预测变量数目不多，并且类别大小差别不大时，k 最近邻算法才能产生非常好的效果。不准确的分类可能会被标记为潜在异常</p></li></ul><p>局限性:</p><p>选择临近的 k 值 影响预测的准确度</p><h4 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h4><p>一句话介绍：世界不是非黑即白，可能还有灰色地带</p><p><img src="https://s3.amazonaws.com/nemolaw/SVM.png" alt="看图吧"></p><p>局限性:</p><ul><li><p>不适合小数据集：样本量少意味着用来对分界线进行准确定位的数据也少</p></li><li><p>不适合多组数据：支持向量机每次只能对两组进行分类。解决方法之一是 多类支持向量机</p></li><li><p>要是数据存在大量重叠：当两组的数据点存在大量重叠时，靠近边界的数据点可能更容易发生分类错误</p></li></ul><h4 id="决策树-和-随机森林"><a href="#决策树-和-随机森林" class="headerlink" title="决策树 和 随机森林"></a>决策树 和 随机森林</h4><p>决策树通过询问一系列二元选择题来做预测.</p><p>随机森林: [群体的智慧](<a href="https://zh.wikipedia.org/wiki/" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/</a> 群体的智慧)</p><blockquote><p>通过随机组合变量来构建多棵决策树，然 后把这些决策树聚集起来，形成随机森林。每个随机的决策树都有自己的问题，但因为最优答案只有一个，通过组合具有不同优缺点的模型，往往能强化正确的预测结果</p></blockquote><p>特点:</p><ul><li>自助聚集法</li></ul><p>通过随机化的方式，使随机生成的决策树之间的关联度最小</p><ul><li>集成方法</li></ul><p>相比于子模型，集成模型的预测准确度更高 (本例遵循少数服从多数的原则). 这是因为准确的预测模型会彼此强 化，错误的则会彼此抵消.</p><p>关键是: * 子模型避免犯同样的错误 *</p><h4 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h4><p>这里我觉得有点奇怪，概念上是分为：输入层，隐藏层，输出层，损失层。但我们的神经并不是层次的，我们对世界的认知并不是层次递进的，更像一个 <a href="https://westworld.fandom.com/wiki/The_Maze" target="_blank" rel="noopener">Maze. (来自西部世界的概念).</a></p><h3 id="A-Btest-和-多臂老虎机"><a href="#A-Btest-和-多臂老虎机" class="headerlink" title="A/Btest 和 多臂老虎机"></a>A/Btest 和 多臂老虎机</h3><p><img src="https://s3.amazonaws.com/nemolaw/epsilon.png" alt="看图吧"></p><p>A/B 测试：探索新的可能性，还是应该利用已有的一切？一种策略是先探索可用选项，然后把所有剩余资源分配给表现最佳的选项.</p><p>epsilon 递减策略：给表现最佳的选项逐渐分配更多的资源.</p><p>虽然 epsilon 递减策略在大多数情况下能够提供比 A/B 测试更高 的回报，但是确定资源分配的最佳更新速度并非易事.</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>知道了概念，看代码至少让你有一个方向。我接下来会去看推到过程么？当然不会，先作为一个实用主义者去踩坑.</p><p>随机森林体现的集体智慧，A/Btest 的策略选择游戏。这两个感觉可以单独成篇.</p></div><div class="reward-container"><div>欢迎用Dogecoin支持我不断记录</div><button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'>支持</button><div id="qr" style="display:none"><div style="display:inline-block"><img src="/images/nemo-dogecoin-address.png" alt="NemoLaw Dogecoin"><p>Dogecoin</p></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/20-%E7%9A%84%E6%94%B6%E8%8E%B7/" rel="tag"><i class="fa fa-tag"></i> 20%的收获</a> <a href="/tags/%E6%95%B0%E7%90%86%E7%9F%A5%E8%AF%86/" rel="tag"><i class="fa fa-tag"></i> 数理知识</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2019/04/13/20190413note/" rel="prev" title="0413 基础知识其实是一种路径优化"><i class="fa fa-chevron-left"></i> 0413 基础知识其实是一种路径优化</a></div><div class="post-nav-item"><a href="/2019/04/14/20190414note/" rel="next" title="吸引力法则：假如你渴望某些东西，先假装你已经拥有">吸引力法则：假如你渴望某些东西，先假装你已经拥有 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments"><div id="disqus_thread"><noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript></div></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据科学的四个步骤"><span class="nav-number">1.</span> <span class="nav-text">数据科学的四个步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据的准备"><span class="nav-number">1.1.</span> <span class="nav-text">数据的准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为模型选择合适的算法-书的重点"><span class="nav-number">1.2.</span> <span class="nav-text">为模型选择合适的算法 (书的重点)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#调整算法参数，优化模型"><span class="nav-number">1.3.</span> <span class="nav-text">调整算法参数，优化模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#根据准确度评价模型"><span class="nav-number">1.4.</span> <span class="nav-text">根据准确度评价模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#算法"><span class="nav-number">2.</span> <span class="nav-text">算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#无监督学习"><span class="nav-number">2.1.</span> <span class="nav-text">无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#K-均值聚类"><span class="nav-number">2.1.1.</span> <span class="nav-text">K 均值聚类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#主成分分析"><span class="nav-number">2.1.2.</span> <span class="nav-text">主成分分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#关联规则"><span class="nav-number">2.1.3.</span> <span class="nav-text">关联规则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#社会网络分析"><span class="nav-number">2.1.4.</span> <span class="nav-text">社会网络分析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#监督学习"><span class="nav-number">2.2.</span> <span class="nav-text">监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#回归分析"><span class="nav-number">2.2.1.</span> <span class="nav-text">回归分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#K-最近邻"><span class="nav-number">2.2.2.</span> <span class="nav-text">K 最近邻</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#支持向量机"><span class="nav-number">2.2.3.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#决策树-和-随机森林"><span class="nav-number">2.2.4.</span> <span class="nav-text">决策树 和 随机森林</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#神经网络"><span class="nav-number">2.2.5.</span> <span class="nav-text">神经网络</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Btest-和-多臂老虎机"><span class="nav-number">2.3.</span> <span class="nav-text">A&#x2F;Btest 和 多臂老虎机</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">3.</span> <span class="nav-text">总结</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="NemoLaw" src="/images/author.jpg"><p class="site-author-name" itemprop="name">NemoLaw</p><div class="site-description" itemprop="description">但盼风雨来，能留你在此</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">248</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">12</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">14</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="mailto:nemo-lxg@outlook.com" title="E-Mail → mailto:nemo-lxg@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fas fa-rss fa-fw"></i>RSS</a> </span><span class="links-of-author-item"><a href="/archives/" title="archives → &#x2F;archives&#x2F;"><i class="fas fa-file-archive fa-fw"></i>archives</a> </span><span class="links-of-author-item"><a href="/categories/" title="categories → &#x2F;categories&#x2F;"><i class="fas fa-th fa-fw"></i>categories</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2015 – <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="heart"></i> </span><span class="author" itemprop="copyrightHolder">nemo-lxg@outlook.com</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">560k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">8:29</span></div><script defer src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon='{"token": "eafd7ba3dbda4f7a8bc9b6c0b096c5fb", "spa": true}'></script><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script><script>window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://nemolaw.com/2019/04/13/begin-machinelearning/',]
      });
      });</script><script>function loadCount(){var d=document,n=d.createElement("script");n.src="https://luoxugeng12581.disqus.com/count.js",n.id="dsq-count-scr",(d.head||d.body).appendChild(n)}window.addEventListener("load",loadCount,!1)</script><script>var disqus_config = function() {
    this.page.url = "https://nemolaw.com/2019/04/13/begin-machinelearning/";
    this.page.identifier = "2019/04/13/begin-machinelearning/";
    this.page.title = "(笔记) 白话机器学习算法";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://luoxugeng12581.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });</script></body></html>